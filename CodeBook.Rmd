---
title: "CodeBook"
author: "Sergio Maldonado"
date: "29/6/2020"
output:
  html_document: default
  pdf_document: default
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Getting and Cleaning Data Project
### Description

This project is part of the Getting and Cleaning Data course from Johns Hopkins University on Coursera.org.

The purpose of this project is to demonstrate your ability to collect, work with, and clean a data set. The goal is to prepare tidy data that can be used for later analysis.

1. A tidy data set as described below,
2. A link to a Github repository with your script for performing the analysis,
3. A code book that describes the variables, the data, and any transformations or work that you performed to clean up the data called CodeBook.md. You should also include a README.md in the repo with your scripts. This repo explains how all of the scripts work and how they are connected.


### Source Data

One of the most exciting areas in all of data science right now is wearable computing - see for example this article . Companies like Fitbit, Nike, and Jawbone Up are racing to develop the most advanced algorithms to attract new users. The data linked to from the course website represent data collected from the accelerometers from the Samsung Galaxy S smartphone. A full description is available at the site where the data was obtained:

Description can be found here [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)

Here are the data for the project:
[Data Set](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip)

### Loading required packages

```{r, message=FALSE}
library(dplyr)
library(data.table)
```
### Downloaded the dataset
```{r, message=FALSE}
filename <- "Getting_Cleaning_Dataset.zip"
# Checking if archieve already exists.
if (!file.exists(filename)){
  fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
  download.file(fileURL, filename, method="curl")
}

# Checking if folder exists
if (!file.exists("UCI HAR Dataset")) { 
  unzip(filename) 
}
```
## **Part 1 - Merge the training and the test sets to create one data set**
Read .txt files into data frames


- This project will use six data, which are `x_train.txt`, `x_test.txt`, `y_train.txt`, `y_test.txt`, `subject_train.txt` and `subject_test.txt`, they can all be found inside the downloaded dataset, namely URI HAR Dataset.
- The ``features.txt` (561 rows, 2 columns) contains the correct variable name, which corresponds to each column of `x_train.txt` with 7352 rows, 561 columns
contains recorded features train data and `x_test.txt` with 2947  rows, 561 columns contains recorded features test data. Further explanation of each feature is in the `features_info.txt`.
- The `activity_labels.txt`  6 rows, 2 columns List of activities performed when the corresponding measurements were taken and its codes (labels) which corresponds to each number in the `y_train.txt` (7352  rows, 1 columns) and `y_test.txt` (2947 rows, 1 columns).
- The `README.txt` is the overall desciption about the overall process of how publishers of this dataset did the experiment and got the data result.




Activity (1 to 6) (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
```{r, message=FALSE}
#features and activities labels
features <- data.table::fread("UCI HAR Dataset/features.txt", col.names = c("n","functions"))
activities <- data.table::fread("UCI HAR Dataset/activity_labels.txt", col.names = c("code", "activity"))
```
>An alternative is: `features <- data.table::fread("UCI HAR Dataset/features.txt", col.names = c("n","functions"))`


Subjects group of 30 volunteers

```{r, message=FALSE}
subject_test <- data.table::fread("UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
subject_train <- data.table::fread("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
```

Data where 70% of the volunteers was selected for generating the training data and 30% the test data, and Activity (1 to 6)
```{r, message=FALSE}
x_train <- data.table::fread("UCI HAR Dataset/train/X_train.txt", col.names = features$functions)
x_test <- data.table::fread("UCI HAR Dataset/test/X_test.txt", col.names = features$functions)
y_test <- data.table::fread("UCI HAR Dataset/test/y_test.txt", col.names = "code")
y_train <- data.table::fread("UCI HAR Dataset/train/y_train.txt", col.names = "code")
```
Combine test and train activities
```{r, message=FALSE}
X<-rbind(x_train,x_test)
Y<-rbind(y_train,y_test)

```
combine subject and combine all data
```{r, message=FALSE}
Subject<-rbind(subject_train,subject_test)
All_data<-cbind(Subject,X,Y)
```

## **Part 2 - Extracts only the measurements on the mean and standard deviation for each measurement.**

```{r, message=FALSE}
TidyData<-select(All_data,subject,code,contains("mean()"),contains("std()"))
```
## **Part 3 - Uses descriptive activity names to name the activities in the data set.**
There are some ways to do that, the easy way is to use data.table library
We use rows from `Tidydata$code` and then we assign the value of `activity` column from `activities`
```{r, message=FALSE}
TidyData$code<-activities[TidyData$code,activity]
```
## **Part 4 - Appropriately labels the data set with descriptive variable names.**

There are a few things to denote:
- "t" = time
- "f" = frequency
- "Acc" = Accelerometer
- "Mag" = Magnitude
- "Gyro" = Gyroscopic
- "Freq" = Frequency
- "stimed" = estimated

```{r, message=FALSE}
names(TidyData)[2] <- "activity"
#colnames(TidyData)[2]<-"activity"
names(TidyData)<-gsub("Acc", "Accelerometer", names(TidyData))
names(TidyData)<-gsub("Gyro", "Gyroscope", names(TidyData))
names(TidyData)<-gsub("BodyBody", "Body", names(TidyData))
names(TidyData)<-gsub("Mag", "Magnitude", names(TidyData))
names(TidyData)<-gsub("^t", "Time", names(TidyData))
names(TidyData)<-gsub("^f", "Frequency", names(TidyData))
names(TidyData)<-gsub("tBody", "TimeBody", names(TidyData))
names(TidyData)<-gsub("-mean()", "Mean", names(TidyData), ignore.case = TRUE)
names(TidyData)<-gsub("-std()", "STD", names(TidyData), ignore.case = TRUE)
names(TidyData)<-gsub("-freq()", "Frequency", names(TidyData), ignore.case = TRUE)
names(TidyData)<-gsub("angle", "Angle", names(TidyData))
names(TidyData)<-gsub("gravity", "Gravity", names(TidyData))
```

## **Part 5 - From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.**

Using dplyr package and use summarise function, by adding across(everything())
```{r, message=FALSE}
tidyDataset <- TidyData %>% group_by(subject,activity) %>% 
  summarise(across(everything(),mean))
write.table(tidyDataset, file = "tidyDataset.txt", row.names = FALSE)
data.table::fwrite(x = tidyDataset, file = "tidyData.csv", quote = FALSE)
```
## **Results Description**

The final tidy data is produced inside the run_analysis.R, which I simply named it tidyDataset.txt and tidyData.csv
Both are the same result, the differences is the format.The tidy data produced after going through all 5 steps of the course project. It contains 180 observations and 68 variables. Where the first column is the subject id, second column is the activity and the rest are the average of each feature variables.
To sum up tidyDataset (180 rows, 88 columns) is created by sumarizing TidyData taking the means of each variable for each activity and each subject, after groupped by subject and activity.

```{r, message=FALSE}
str(tidyDataset)
```

```{r, message=FALSE}
tidyDataset
```


